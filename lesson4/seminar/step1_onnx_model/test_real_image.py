from src.model_converter import BlipONNXConverter
from src.onnx_tester import ONNXModelTester
from PIL import Image
import os
import torch
import numpy as np


def test_with_real_image():
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    """
    print("=== –¢–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º ===\n")

    # –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    image_path = "../step2_fastapi_inference/test_images/img.jpg"

    if not os.path.exists(image_path):
        print(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
        return

    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–∫–∞–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    image = Image.open(image_path)
    print(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.size}")
    print(f"–†–µ–∂–∏–º: {image.mode}")

    # –¢–µ—Å—Ç PyTorch –º–æ–¥–µ–ª–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    print("\n1. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ PyTorch –º–æ–¥–µ–ª–∏:")
    converter = BlipONNXConverter()
    converter.load_model()

    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    inputs = converter.processor(image, return_tensors="pt")
    print(f"–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {inputs.pixel_values.shape}")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è caption PyTorch –º–æ–¥–µ–ª—å—é

    with torch.no_grad():
        out = converter.model.generate(**inputs, max_length=50)

    caption = converter.processor.decode(out[0], skip_special_tokens=True)
    print(f"PyTorch –º–æ–¥–µ–ª—å caption: '{caption}'")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX –º–æ–¥–µ–ª–∏
    print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX –º–æ–¥–µ–ª–∏:")
    onnx_path = "models/blip_model.onnx"

    if not os.path.exists(onnx_path):
        print("‚ùå ONNX –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞–µ–º...")
        converter.convert_to_onnx(onnx_path)

    # –¢–µ—Å—Ç ONNX —Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    tester = ONNXModelTester(onnx_path)
    tester.load_onnx_model()

    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ ONNX
    try:
        inputs_onnx = converter.processor(image, return_tensors="pt")
        image_input = inputs_onnx.pixel_values.numpy()
        # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π token_id –¥–ª—è BLIP (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        token_id = getattr(converter.processor.tokenizer, "bos_token_id", None)
        if token_id is None:
            token_id = getattr(converter.processor.tokenizer, "cls_token_id", 101)

        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º token_id: {token_id}")
        input_ids = np.array(
            [[token_id] * 16], dtype=np.int64
        )  # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä [1, 16]

        print("–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è ONNX:")
        print(f"  - image: {image_input.shape} {image_input.dtype}")
        print(f"  - input_ids: {input_ids.shape} {input_ids.dtype}")

        # ONNX –∏–Ω—Ñ–µ—Ä–µ–Ω—Å —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –≤—Ö–æ–¥–∞–º–∏
        onnx_inputs = {"image": image_input, "input_ids": input_ids}

        print("\nüöÄ –ó–∞–ø—É—Å–∫ ONNX –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...")
        outputs = tester.session.run(None, onnx_inputs)
        print(f"‚úÖ ONNX —Ä–∞–±–æ—Ç–∞–µ—Ç! –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–æ–≤: {len(outputs)}")

        # –ê–Ω–∞–ª–∏–∑ –≤—ã—Ö–æ–¥–æ–≤
        for i, output in enumerate(outputs):
            print(f"  –í—ã—Ö–æ–¥ {i}: {output.shape}")

        # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –≤—ã—Ö–æ–¥–∞ (–ª–æ–≥–∏—Ç—ã)
        logits = outputs[0]  # [1, 16, 30524]
        if len(logits.shape) == 3 and logits.shape[2] == 30524:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–æ–∫–µ–Ω –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            last_token_logits = logits[0, -1, :]  # [30524]
            predicted_id = int(np.argmax(last_token_logits))

            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω
            try:
                predicted_token = converter.processor.tokenizer.decode([predicted_id])
                print(
                    f"\nüéØ ONNX –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω: '{predicted_token}' (ID: {predicted_id})"
                )

                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                top5_ids = np.argsort(last_token_logits)[-5:][::-1]
                print("–¢–æ–ø-5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤:")
                for rank, tid in enumerate(top5_ids, 1):
                    try:
                        token = converter.processor.tokenizer.decode([tid])
                        prob = float(last_token_logits[tid])
                        print(f"  {rank}. '{token}' (ID: {tid}, –ª–æ–≥–∏—Ç: {prob:.2f})")
                    except Exception:
                        print(f"  {rank}. <token_{tid}> (ID: {tid})")

            except Exception as decode_error:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω {predicted_id}: {decode_error}")

        print("\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        print(f"‚úÖ PyTorch –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: '{caption}'")
        print(f"‚ö†Ô∏è  ONNX –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω: '{predicted_token}' (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ç–æ–∫–µ–Ω)")
        print("\nüí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ:")
        print("   PyTorch –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–ª–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞ (autoregressive)")
        print("   ONNX —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —à–∞–≥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–∞")
        print("   –î–ª—è –ø–æ–ª–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å ONNX –º–æ–¥–µ–ª—å")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ONNX: {e}")

    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("üì∏ PyTorch –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
    print(f"üí¨ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: '{caption}'")


if __name__ == "__main__":
    test_with_real_image()
